{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "97b83ab8",
   "metadata": {},
   "source": [
    "# 5. 분류 (classification)\n",
    "분류는 대상의 속성을 입력 받고, 목표 변수가 갖고 있는 카테고리(범주형) 값 중에서 분류하여 예측한다. 목표 변수 값을 함께 입력하기 때문에 지도 학습 유형에 속하는 알고리즘이다.  \n",
    "KNN, SVM, Decision Tree, Logistic Regression 등의 알고리즘이 존재한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6996de8b",
   "metadata": {},
   "source": [
    "## KNN (k-Nearest-Neighbors)\n",
    "KNN은 k개의 가까운 이윳이라는 뜻이다. 관측값이 주어지면 관측값을 기준으로 가까운 순서로 k개의 속성을 찾고, 가장 많은 속성으로 분류한다.  \n",
    "이때 k값에 따라 정확도가 달라지므로 적절한 k값을 찾는 것이 매우 중요하다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "869776ce",
   "metadata": {},
   "source": [
    "데이터는 Seaborn 라이브러리에서 'titanic'데이터 셋을 활용한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2c93c8d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   survived  pclass     sex   age  sibsp  parch     fare embarked  class  \\\n",
      "0         0       3    male  22.0      1      0   7.2500        S  Third   \n",
      "1         1       1  female  38.0      1      0  71.2833        C  First   \n",
      "2         1       3  female  26.0      0      0   7.9250        S  Third   \n",
      "3         1       1  female  35.0      1      0  53.1000        S  First   \n",
      "4         0       3    male  35.0      0      0   8.0500        S  Third   \n",
      "\n",
      "     who  adult_male deck  embark_town alive  alone  \n",
      "0    man        True  NaN  Southampton    no  False  \n",
      "1  woman       False    C    Cherbourg   yes  False  \n",
      "2  woman       False  NaN  Southampton   yes   True  \n",
      "3  woman       False    C  Southampton   yes  False  \n",
      "4    man        True  NaN  Southampton    no   True  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "df = sns.load_dataset('titanic')\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc08b5e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 15 columns):\n",
      " #   Column       Non-Null Count  Dtype   \n",
      "---  ------       --------------  -----   \n",
      " 0   survived     891 non-null    int64   \n",
      " 1   pclass       891 non-null    int64   \n",
      " 2   sex          891 non-null    object  \n",
      " 3   age          714 non-null    float64 \n",
      " 4   sibsp        891 non-null    int64   \n",
      " 5   parch        891 non-null    int64   \n",
      " 6   fare         891 non-null    float64 \n",
      " 7   embarked     889 non-null    object  \n",
      " 8   class        891 non-null    category\n",
      " 9   who          891 non-null    object  \n",
      " 10  adult_male   891 non-null    bool    \n",
      " 11  deck         203 non-null    category\n",
      " 12  embark_town  889 non-null    object  \n",
      " 13  alive        891 non-null    object  \n",
      " 14  alone        891 non-null    bool    \n",
      "dtypes: bool(2), category(2), float64(2), int64(4), object(5)\n",
      "memory usage: 80.7+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87cca7ec",
   "metadata": {},
   "source": [
    "데이터에서 NaN 값이 많은 열을 삭제하고 전처리를 진행하자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "465da7d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['survived' 'pclass' 'sex' 'age' 'sibsp' 'parch' 'fare' 'embarked' 'class'\n",
      " 'who' 'adult_male' 'alive' 'alone']\n"
     ]
    }
   ],
   "source": [
    "rdf = df.drop(['deck','embark_town'], axis=1) # axis=1 열 기준 연산\n",
    "print(rdf.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d2cd8acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdf = rdf.dropna(subset=['age'], how='any', axis=0)\n",
    "\n",
    "most_freq = rdf['embarked'].value_counts(dropna=True).idxmax() # print(rdf.describe(include='all'))\n",
    "rdf['embarked'].fillna(most_freq, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e81d60f2",
   "metadata": {},
   "source": [
    "분석에 사용할 속성을 지정하고, get_dummies를 활용하여 원핫인코딩을 적용하고 prefix 옵션을 사용하여 접두어를 붙여주자.  \n",
    "##### Q1. 원핫인코딩이 뭐지\n",
    "- onehot\n",
    "- get_dummies\n",
    "- prefix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "312a15c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ndf = rdf[['survived','pclass','sex','age','sibsp','parch','embarked']]\n",
    "\n",
    "onehot_sex = pd.get_dummies(ndf['sex'])\n",
    "ndf = pd.concat([ndf, onehot_sex], axis=1)\n",
    "\n",
    "onehot_embarked = pd.get_dummies(ndf['embarked'], prefix='town')\n",
    "ndf = pd.concat([ndf, onehot_embarked], axis=1) #axis=1 : 열 기준 연산\n",
    "\n",
    "ndf.drop(['sex','embarked'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37863a0d",
   "metadata": {},
   "source": [
    "독립변수를 지정하고  \n",
    "StandardScaler()preprocessing.StandardScalar().fit(X).transform(X)을 활용하여  \n",
    "데이터의 상대적 크기 차이를 없애기 위하여 데이터 정규화(normalization)을 진행한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3f3e3246",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=ndf[['pclass','age','sibsp','parch','female','male',\n",
    "      'town_C','town_Q','town_S']] #독립 변수 X\n",
    "y=ndf['survived']\n",
    "\n",
    "from sklearn import preprocessing\n",
    "X = preprocessing.StandardScaler().fit(X).transform(X) # standardScaler => 통계화 시킴.\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                    test_size=0.3,\n",
    "                                                    random_state=10)\n",
    "# 트레이닝 데이터와 테스트 데이터를 split으로 분리"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "795326c5",
   "metadata": {},
   "source": [
    "사이킷런에서 KNeighborsClassifier를 통해 KNN 분류 모형을 가져오자. 이때 k값을 넣어준다. 비지도라 k값은 알 수가 없고 여러개 해보고 제일 좋은 것을 선택한다. 그리고 학습을 진행하고 예측값과 결과값을 비교해 보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ea89ebdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1 0 0 1 1 1 0 0]\n",
      "[0 0 1 0 0 1 1 1 0 0]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier #최 근접 분류모델을 쓴다.\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(X_train, y_train)\n",
    "y_hat = knn.predict(X_test)\n",
    "\n",
    "print(y_hat[0:10])\n",
    "print(y_test.values[0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "358ec468",
   "metadata": {},
   "source": [
    "모형의 예측 능력을 평가해 보자. metrics 모듈의 confusion_matrix()함수를 사용하여 Confusion Matrix를 계산하자. 그리고 classification_report() 함수를 사용하여 precision, recall, f1-score 지표를 출력해준다. 관련 개념은 코드 아래 부분을 참고하자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e91c2542",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[109  16]\n",
      " [ 25  65]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.87      0.84       125\n",
      "           1       0.80      0.72      0.76        90\n",
      "\n",
      "    accuracy                           0.81       215\n",
      "   macro avg       0.81      0.80      0.80       215\n",
      "weighted avg       0.81      0.81      0.81       215\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "knn_matrix = metrics.confusion_matrix(y_test, y_hat) # 매트릭스 => 평가 측정 지표\n",
    "print(knn_matrix)\n",
    "\n",
    "knn_report = metrics.classification_report(y_test, y_hat) #정리해서 도출되기 때문에 R보다 좋다\n",
    "print(knn_report) # confusion_matrix는 헷갈리고 시험도 많이 나온다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c38ac92f",
   "metadata": {},
   "source": [
    "## 분류 모형의 예측력을 평가하는 지표\n",
    "\n",
    "1. Confusion Matrix\n",
    "2. Precision (정확도)\n",
    "3. Recall (재현율)\n",
    "4. F1-score (F1 지표)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbdccacc",
   "metadata": {},
   "source": [
    "### 1. Confusion Matrix\n",
    "모형을 예측하는 값에는 True와 False가 있다. 그리고 아래의 그림과 같이 모형의 예측값과 실제 값을 각각 축으로 하는 2x2 매트릭스로 표현한 것을 Confusion Matrix라고 부른다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40a4cf69",
   "metadata": {},
   "source": [
    "|예측값|||\n",
    "|:------:|:---:|:---:|\n",
    "|T|TP (True Positive)|FP (False Positive)|\n",
    "|F|FN (False Negative)|TN (True Negative)|\n",
    "|실제값|T|F|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "229e6497",
   "metadata": {},
   "source": [
    "### 2. 정확도 (Precision)\n",
    "True로 예측한 분석대상 중에서 실제 값이 True인 비율을 말하며, 모형의 정확성을 나타내는 지표가 된다. 정확도가 높다는 것은 False Positive(실제 False를 True로 잘못 예측) 오류가 적다는 말이다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02b6f3c9",
   "metadata": {},
   "source": [
    "$$ Precision = \\frac{TP}{TP+FP}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d840acf4",
   "metadata": {},
   "source": [
    "### 3. 재현율 (Recall)\n",
    "실제 값이 True인 분석대상 중에서 True로 예측하여 모형이 적중한 비율을 말하며, 모형의 완전성을 나타내는 지표이다.  \n",
    "재현율이 높다는 것은 False Negative(실제 True를 False로 잘못 예측) 오류가 낮다는 뜻이다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a75d872",
   "metadata": {},
   "source": [
    "$$ Recall = \\frac{TP}{TP+FN} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd7f9a4b",
   "metadata": {},
   "source": [
    "### 4. F1 지표 (F1-score)\n",
    "정확도와 재현율이 균등하게 반영될 수 있도록 정확도와 재현율의 조화평균을 계산한 값으로, 모형의 예측력을 종합적으로 평가하는 지표이다.  \n",
    "값이 높을수록 분류 모형의 예측력이 좋다고 말할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16fb1811",
   "metadata": {},
   "source": [
    "$$ F1 score = 2*\\frac{Precision*Recall}{Precision+Recall}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "05e0b4dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1 0 0 0 1 0 1 0]\n",
      "[0 0 1 0 0 1 1 1 0 0]\n",
      "[[118   7]\n",
      " [ 38  52]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.94      0.84       125\n",
      "           1       0.88      0.58      0.70        90\n",
      "\n",
      "    accuracy                           0.79       215\n",
      "   macro avg       0.82      0.76      0.77       215\n",
      "weighted avg       0.81      0.79      0.78       215\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier #최 근접 분류모델을 쓴다.\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=19) # k값\n",
    "# k 값이 크다도 무작정 좋은 것이 아닌거 같다. 그냥 여러가지를 해보고 가장 적당한 것을 결과로 뽑는것이 좋다.\n",
    "knn.fit(X_train, y_train)\n",
    "y_hat = knn.predict(X_test)\n",
    "\n",
    "print(y_hat[0:10])\n",
    "print(y_test.values[0:10])\n",
    "\n",
    "from sklearn import metrics\n",
    "knn_matrix = metrics.confusion_matrix(y_test, y_hat) # 매트릭스 => 평가 측정 지표\n",
    "print(knn_matrix)\n",
    "\n",
    "knn_report = metrics.classification_report(y_test, y_hat) #정리해서 도출되기 때문에 R보다 좋다\n",
    "print(knn_report) # confusion_matrix는 헷갈리고 시험도 많이 나온다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "838e43dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "insert cycle: 5\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'KNeighborsClassifier' object does not support item assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-e2c9fee43376>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mknn\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mknn\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKNeighborsClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_neighbors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# k값\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'KNeighborsClassifier' object does not support item assignment"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier #최 근접 분류모델을 쓴다.\n",
    "from sklearn import metrics\n",
    "\n",
    "a = int(input('insert cycle: '))\n",
    "\n",
    "for i in range(1,a):\n",
    "    knn[0] = 0\n",
    "    knn[i] = KNeighborsClassifier(n_neighbors=i) # k값\n",
    "    \n",
    "\n",
    "    knn[i].fit(X_train, y_train)\n",
    "    y_hat = knn[i].predict(X_test)\n",
    "\n",
    "    print(y_hat[0:10])\n",
    "    print(y_test.values[0:10])\n",
    "\n",
    "\n",
    "    knn_matrix[i] = metrics.confusion_matrix(y_test, y_hat) # 매트릭스 => 평가 측정 지표\n",
    "    a = knn_matrix[i].sum()\n",
    "    b = knn_matrix[i+1].sum()\n",
    "    if knn_matrix[i].sum() > knn_matrix[i+1].sum():\n",
    "        print(knn_matrix[i])\n",
    "    else:\n",
    "        print(knn_matrix[i+1])\n",
    "\n",
    "    knn_report = metrics.classification_report(y_test, y_hat) #정리해서 도출되기 때문에 R보다 좋다\n",
    "    print(knn_report) # confusion_matrix는 헷갈리고 시험도 많이 나온다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e2caff2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
